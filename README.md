Real-Time Recommendation System with End-to-End MLOps

A production-grade real-time recommendation system built from scratch using modern MLOps practices.
This project demonstrates online learning, feature stores, vector search, monitoring, drift detection, automated retraining, cold-start handling, and MLflow model governance.

âš ï¸ This is not a toy project or notebook demo â€” it is a full system designed like real production recommender platforms (Netflix / Amazon-style).

ğŸ§  Problem Statement

Traditional recommendation systems are:

Batch-trained

Slow to adapt to user behavior

Hard to monitor and retrain

This project solves that by building a real-time recommender that:

Learns continuously from streaming events

Handles cold-start users & items

Detects data & concept drift automatically

Retrains itself without human intervention

Tracks experiments and model versions using MLflow

ğŸ—ï¸ High-Level Architecture
Client
  â”‚
  â–¼
FastAPI (Serving + Swagger)
  â”‚
  â”œâ”€â”€ Feature Fetch (Feast + Redis)
  â”œâ”€â”€ Cold-Start Detection
  â”œâ”€â”€ Two-Tower User Embedding
  â”œâ”€â”€ ANN Retrieval (Milvus)
  â”œâ”€â”€ Ranking Layer
  â”‚
  â–¼
Recommendations
  â”‚
  â–¼
Kafka (User Events)
  â”‚
  â”œâ”€â”€ Online Learning Updates
  â”œâ”€â”€ Feature Updates (Feast)
  â”œâ”€â”€ Counterfactual Logging (IPS / DR)
  â”‚
  â–¼
Monitoring + Drift Detection
  â”‚
  â”œâ”€â”€ Prometheus / Grafana
  â”œâ”€â”€ Drift Watchdog
  â”‚
  â–¼
MLflow Retraining Pipeline

âœ¨ Key Features
ğŸ”¹ Real-Time Streaming

Kafka-based ingestion of user events (views, clicks, purchases)

Near-instant feedback loop

ğŸ”¹ Feature Store (Feast)

Offline + online feature consistency

Redis-backed low-latency feature serving

ğŸ”¹ Two-Tower Recommendation Model

Separate user and item towers

Efficient embedding-based retrieval

ğŸ”¹ ANN Search (Milvus)

Production-grade vector database

Fast candidate generation at scale

ğŸ”¹ Ranking Layer

Post-retrieval ranking with business signals

Cold-item exploration boost

ğŸ”¹ Online Learning

Incremental updates from streaming events

Real-time adaptation to user behavior

ğŸ”¹ Cold-Start Strategy

Feature-store-based cold user detection

Popularity-based fallback

Exploration for new items

ğŸ”¹ Counterfactual Evaluation

IPS (Inverse Propensity Scoring)

Doubly Robust (DR) estimation

Offline evaluation without risky A/B tests

ğŸ”¹ Drift Detection & Auto-Retraining

Feature drift + reward drift monitoring

Automatic retraining triggers

Cool-down protection

ğŸ”¹ MLflow Integration

Experiment tracking

Model versioning

Model registry (Staging â†’ Production)

Drift-triggered retraining runs logged automatically

ğŸ”¹ Monitoring & Observability

Prometheus metrics

Grafana dashboards

Latency, throughput, cold-start rate

ğŸ› ï¸ Tech Stack
Category	Tools
API	FastAPI, Swagger
Streaming	Kafka
Feature Store	Feast + Redis
Vector Search	Milvus
ML	PyTorch
MLOps	MLflow
Monitoring	Prometheus, Grafana
Serving	Uvicorn
Language	Python
â–¶ï¸ How to Run the Project
1ï¸âƒ£ Clone Repository
git clone https://github.com/USERNAME/real-time-recommendation-mlops.git
cd real-time-recommendation-mlops

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

3ï¸âƒ£ Start MLflow
mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns


Open:

http://127.0.0.1:5000

4ï¸âƒ£ Train & Register Model
python -m retrieval.train


Promote model to Production in MLflow UI.

5ï¸âƒ£ Start API
uvicorn serving.app:app --reload


Swagger UI:

http://127.0.0.1:8000/docs

6ï¸âƒ£ Start Streaming Components
python -m streaming.consumer
python -m monitoring.watchdog

ğŸ§ª Example API Usage
Known User
GET /recommend/1


Response:

{
  "cold_start": false,
  "recommendations": [12, 5, 42, 8]
}

Cold User
GET /recommend/999999


Response:

{
  "cold_start": true,
  "strategy": "popular_fallback",
  "recommendations": [3, 7, 1, 19]
}

ğŸ“Š MLflow Model Governance

All training runs tracked

Drift-triggered retraining logged

Model promotion controlled via registry

Serving loads Production model automatically

ğŸ¯ Why This Project Is Different

Most ML projects:

Train once

Serve static models

Ignore drift & monitoring

This project:

Learns continuously

Detects when it is wrong

Retrains itself

Tracks everything

Handles real-world edge cases (cold start, exploration, governance)

ğŸ§  What This Demonstrates

Real-time ML systems design

Production MLOps practices

Recommender systems expertise

Strong Python packaging discipline

End-to-end ownership mindset

ğŸ“Œ Future Improvements

True contextual bandits / RL policies

Distributed training

Feature attribution explainability

Cloud deployment (Kubernetes)

ğŸ‘¤ Author

Vaibhav Tiwari
Built as a capstone-level, production-oriented ML system.

â­ If You Like This Project

Give it a â­ on GitHub â€” it helps a lot!

ğŸ‰ Final Note

If youâ€™re reviewing this as a recruiter or interviewer:
This project reflects how real ML systems are built and operated in production, not just academic modeling.
